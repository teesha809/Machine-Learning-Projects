{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4267b787",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we'll write python script that captures images from your webcam video stream\n",
    "# we'll be extracting all faces from the image frame (using haarcascades classifier)\n",
    "# after that we will store the face information using numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e27b3a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Read and show video stream, capture images\n",
    "# 2. Detect faces and show bounding box (haarcascade)\n",
    "# 3. Flatten the largest face image(gray scale) and save in numpy array\n",
    "# 4. Repeat this for multiple people to generate training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc174c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing necessary libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# face recognition\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fabe5caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing webcam\n",
    "# cap = cv2.VideoCapture(0) # 0 indicates default device webcam id \n",
    "# different webcams connected to same device have different id's "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ed76ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pretrained classifier - haarcadcade classifier => show bounding images => use adaboost => read frontal page\n",
    "# eye recogz , face recoz\n",
    "# showing bounding box across each face\n",
    "\n",
    "# Face Detection\n",
    "# creating object of face cascade classifier\n",
    "\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_alt.xml\")\n",
    "\n",
    "if face_cascade.empty():\n",
    "    print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc0fcf17",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1156064248.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [2]\u001b[1;36m\u001b[0m\n\u001b[1;33m    np.save()?\u001b[0m\n\u001b[1;37m             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "np.save()?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b460d7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0) \n",
    "\n",
    "face_data = []\n",
    "dataset_path = \"../FaceData Collect/\"\n",
    "file_name = input(\"Enter the name of person : \")\n",
    "\n",
    "# face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"../haarcascade_frontalface_alt.xml\")\n",
    "\n",
    "\n",
    "# here, we are capturing images from webcam\n",
    "while True:\n",
    "    \n",
    "    # read frame \n",
    "    # 2 values = bool (frame captured?) , frame value (array)\n",
    "    read_frame, frame_val = cap.read()\n",
    "    \n",
    "    if read_frame==False:\n",
    "        continue\n",
    "        \n",
    "    # converting the frame into gray scale\n",
    "    gray_frame = cv2.cvtColor(frame_val, cv2.COLOR_BGR2GRAY)   \n",
    "    \n",
    "    # 3 param\n",
    "    # 1. gray_frame   2. scaling factor = reducing dimention of image by a factor \n",
    "    # 3. minimum number of neighbours => higher number lower resolution capacity (3-6)\n",
    "    # opencv frontal face detection\n",
    "    faces = face_cascade.detectMultiScale(gray_frame, 1.3, 5)\n",
    "    \n",
    "    # faces have 5 values\n",
    "    #  [(x,y,w,h), (....), (....), ....] => 4 coordinates(x,y,width,height) = list of tuples\n",
    "    \n",
    "    if len(faces)==0:\n",
    "        continue\n",
    "    \n",
    "    # sorting faces based on area => largest face among box detected=> sorted based on area => width*height\n",
    "    faces = sorted(faces, key=lambda f:f[2]*f[3])\n",
    "    \n",
    "    # picking last face cause it has largest area\n",
    "    for face in faces[-1:]:\n",
    "        # drawing bounding box [rectangle]\n",
    "        x,y,w,h = face\n",
    "        # cv2.rectangle(frame, starting_coordinate, ending_coordinate, color, thickness)\n",
    "        cv2.rectangle(gray_frame, (x,y), (x+w,y+h), (0,255,0), 2)\n",
    "        \n",
    "        # extract (crop out required face) : region of interest\n",
    "        offset = 10\n",
    "        face_section = gray_frame[y-offset:y+h+offset, x-offset:x+w+offset]\n",
    "        face_section = cv2.resize(face_section,(100,100))\n",
    "        face_data.append(face_section)\n",
    "        print(len(face_section))\n",
    "    \n",
    "    \n",
    "    # show image using cv2.imshow()\n",
    "#     cv2.imshow(\"frame\", frame_val)\n",
    "    \n",
    "    # applying haarcascade to gray frame \n",
    "    cv2.imshow(\"gray_frame\", gray_frame)\n",
    "    \n",
    "    # when will loop break\n",
    "    # for breaking the loop, click any keyboard button\n",
    "    \n",
    "    # key pressed must be 'q' in this fun\n",
    "    key_pressed = cv2.waitKey(1) & 0xFF \n",
    "    # give integer between range of integer and take first 8 bits of integer (bitmask)\n",
    "    \n",
    "    if key_pressed==ord('q'):  # 'ord' gives ASCII value for 'q'\n",
    "        break\n",
    "\n",
    "# convert face_data list to numpy array\n",
    "face_data = np.asarray(face_data)\n",
    "face_data = face_data.reshape((face_data.shape[0],-1))\n",
    "print(face_data.shape)\n",
    "\n",
    "# saving this face_data into file system\n",
    "np.save(dataset_path+file_name,face_data)\n",
    "print(\"Data Saved Successfully!! :)\")\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b68d3a65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78, 10000)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(78, 10000)\n",
    "\n",
    "# 78 frames \n",
    "# for each frame 10000 number of RGB values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "270af5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Recognise Faces using classification algorithm - like Logistic, KNN, SVM etc. => values , labels\n",
    "\n",
    "# 1. load the training data (numpy array of all persons)\n",
    "        # x - values are stored in numpy arrays (values array)\n",
    "        # y - values we need to assign for each person (labels)\n",
    "\n",
    "# 2. Read a video stream using opencv\n",
    "# 3. extract faces out of it\n",
    "# 4. using knn to find the prediction of faces (int)\n",
    "# 5. map predicted id to name of user\n",
    "# 6. Display the predictions on screen - boundary box and name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68db2116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eucledian Distance for KNN\n",
    "def distance(x1, x2):\n",
    "    return np.sqrt(sum((x1-x2)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2be6613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN code\n",
    "\n",
    "def knn(x, y, k=5):\n",
    "    vals = []\n",
    "    \n",
    "    for i in range(x.shape[0]):\n",
    "        xi = x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
